[
  {
    "objectID": "methods/data-aquisition.html",
    "href": "methods/data-aquisition.html",
    "title": "",
    "section": "",
    "text": "This file describing the data acquisition of this project.\nSources for gaining information about the tree species in NRW forests:\n\nWaldmonitor.de [@welle2014]\nDominant tree species by Thuenen: https://atlas.thuenen.de/layers/geonode:Dominant_Species_Class\nValidating with Sentinel RGB imageries the shape and texture of the area:\n\nleaf color\nhuman made /natural shapes of the forest\nHuman made objects in the direct neighboorhoud of the area."
  },
  {
    "objectID": "methods/data-aquisition.html#data-acquisition",
    "href": "methods/data-aquisition.html#data-acquisition",
    "title": "",
    "section": "",
    "text": "This file describing the data acquisition of this project.\nSources for gaining information about the tree species in NRW forests:\n\nWaldmonitor.de [@welle2014]\nDominant tree species by Thuenen: https://atlas.thuenen.de/layers/geonode:Dominant_Species_Class\nValidating with Sentinel RGB imageries the shape and texture of the area:\n\nleaf color\nhuman made /natural shapes of the forest\nHuman made objects in the direct neighboorhoud of the area."
  },
  {
    "objectID": "report.html",
    "href": "report.html",
    "title": "Forest Data Analysis Report",
    "section": "",
    "text": "This report documents the analysis of forest data for different tree species."
  },
  {
    "objectID": "report.html#data-acquisition",
    "href": "report.html#data-acquisition",
    "title": "Forest Data Analysis Report",
    "section": "2.1 Data acquisition",
    "text": "2.1 Data acquisition\nThis file describing the data acquisition of this project.\nSources for gaining information about the tree species in NRW forests:\n\nWaldmonitor.de (Welle et al. 2022)\nDominant tree species by Thuenen: https://atlas.thuenen.de/layers/geonode:Dominant_Species_Class\nValidating with Sentinel RGB imageries the shape and texture of the area:\n\nleaf color\nhuman made /natural shapes of the forest\nHuman made objects in the direct neighboorhoud of the area."
  },
  {
    "objectID": "report.html#preprocessing",
    "href": "report.html#preprocessing",
    "title": "Forest Data Analysis Report",
    "section": "2.2 Preprocessing",
    "text": "2.2 Preprocessing\nIn this research study, the management and processing of a large dataset are crucial considerations. The dataset’s substantial size necessitates careful maintenance to ensure efficient handling. Furthermore, the data should be easily processable and editable to facilitate necessary corrections and precalculations within the context of our research objectives. To achieve our goals, we have implemented a framework that automatically derives data based on a shapefile, delineating areas of interest. The processed data and results of precalculations are stored in a straightforward manner to enhance accessibility. Additionally, we have designed functions that establish a user-friendly interface, enabling the execution of algorithms on subsets of the data, such as distinct species. These interfaces are not only directly callable by users but can also be integrated into other functions to automate processes. The overarching aim is to streamline the entire preprocessing workflow using a single script, leveraging only the shapefile as a basis. This subsection details the accomplishments of our R-package in realizing these goals, outlining the preprocessing steps undertaken and justifying their necessity in the context of our research.\nThe data are stored in a data subdirectory of the root directory in the format species/location-name/tile-name. To automate the matching of areas of interest with the catalog from the Land NRW1, we utilize the intersecting tool developed by Heisig2. This tool, allows for the automatic retrieval and placement of data downloaded from the Land NRW catalog. To enhance data accessibility, we have devised an object that incorporates species, location name, and tile name (the NRW internal identifier) for each area This object facilitates the specification of the area to be processed. Additionally, we have defined an initialization function that downloads all tiles, returning a list of tile location objects for subsequent processing. A pivotal component of the package’s preprocessing functionality is the map function, which iterates over a list of tile locations (effectively the entire dataset) and accepts a processing function as an argument. The subsequent paragraph outlines the specific preprocessing steps employed, all of which are implemented within the mapping function.\nTo facilitate memory-handling capabilities, each of the tiles, where one area can span multiple tiles, has been split into manageable chunks. We employed a 50x50m size for each tile, resulting in the division of original 1km x 1km files into 400 tiles. These tiles are stored in our directory structure, with each tile housed in a directory named after its tile name and assigned an id as the filename. Implementation-wise, the lidr::catalog_retile function was instrumental in achieving this segmentation. The resulting smaller chunks allow for efficient iteration during subsequent preprocessing steps.\nThe next phase involves reducing our data to the actual size by intersecting the tiles with the defined area of interest. Using the lidR::merge_spatial function, we intersect the area derived from the shapefile, removing all point cloud items outside this region. Due to our tile-wise approach, empty tiles may arise, and in such cases, those tiles are simply deleted.\nFollowing the size reduction to our dataset, the next step involves correcting the z values. The z values in the data are originally relative to the ellipsoid used for referencing, but we require them to be relative to the ground. To achieve this, we utilize the lidR::tin function, which extrapolates a convex hull between all ground points (classified by the data provider) and calculates the z value based on this structure.\nSubsequently, we aim to perform segmentation for each distinct tree, marking each item of the point cloud with a tree ID. We employ the algorithm described by Li et al. (2012), using parameters li2012(dt1 = 2, dt2 = 3, R = 2, Zu = 10, hmin = 5, speed_up = 12). The meanings of these parameters are elucidated in Li et al.’s work (Li et al. 2012).\nFinally, the last preprocessing step involves individual tree detection, seeking a single POINT object for each tree. The lidR::lmf function, an implementation of the tree data using a local maximum approach, is utilized for this purpose (Popescu and Wynne 2004). The results are stored in GeoPackage files within our data structure.\nSee Section 5.1 for the implementation of the preprocessing."
  },
  {
    "objectID": "report.html#sec-appendix-preprocessing",
    "href": "report.html#sec-appendix-preprocessing",
    "title": "Forest Data Analysis Report",
    "section": "5.1 Script which can be used to do all preprocessing",
    "text": "5.1 Script which can be used to do all preprocessing\nLoad the file with the research areas ::: {.cell}\nsf &lt;- sf::read_sf(here::here(\"research_areas.shp\"))\nprint(sf)\n\nSimple feature collection with 12 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 7.071625 ymin: 51.08151 xmax: 8.539877 ymax: 52.25983\nGeodetic CRS:  WGS 84\n# A tibble: 12 × 4\n      id species name                                                   geometry\n   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;                                             &lt;POLYGON [°]&gt;\n 1     1 oak     rinkerode           ((7.678922 51.85789, 7.675446 51.85752, 7.…\n 2     2 oak     hamm                ((7.858955 51.66699, 7.866444 51.66462, 7.…\n 3     3 oak     muenster            ((7.618908 51.9154, 7.617384 51.9172, 7.61…\n 4     4 pine    greffen             ((8.168691 51.98965, 8.167178 51.99075, 8.…\n 5     5 pine    telgte              ((7.779728 52.00662, 7.781616 52.00662, 7.…\n 6     6 pine    mesum               ((7.534424 52.25499, 7.53378 52.25983, 7.5…\n 7     7 beech   bielefeld_brackwede ((8.524749 51.9921, 8.528418 51.99079, 8.5…\n 8     8 beech   wuelfenrath         ((7.071625 51.29256, 7.072311 51.29334, 7.…\n 9     9 beech   billerbeck          ((7.324729 51.99783, 7.323548 51.99923, 7.…\n10    10 spruce  marienheide         ((7.558102 51.08358, 7.558317 51.08527, 7.…\n11    11 spruce  brilon              ((8.532195 51.41029, 8.535027 51.41064, 8.…\n12    12 spruce  osterwald           ((8.369328 51.21693, 8.371238 51.21718, 8.…\n\n:::\nInit the project ::: {.cell}\nlibrary(lfa)\nsf::sf_use_s2(FALSE)\nlocations &lt;- lfa_init(\"research_areas.shp\")\n:::\nDo all of the prprocessing steps ::: {.cell}\nlfa_map_tile_locations(locations,retile,check_flag = \"retile\")\n\nNo further processing: flag retile is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_intersect_areas, ctg = NULL, areas_sf = sf,check_flag = \"intersect\")\n\nNo further processing: flag intersect is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_ground_correction, ctg = NULL,check_flag = \"z_correction\")\n\nNo further processing: flag z_correction is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_segmentation, ctg = NULL,check_flag = \"segmentation\")\n\nNo further processing: flag segmentation is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_detection, catalog = NULL, write_to_file = TRUE,check_flag = \"detection\")\n\nNo further processing: flag detection is set!Function is already computed, no further computings here\n\n\nNULL\n\n:::"
  },
  {
    "objectID": "report.html#footnotes",
    "href": "report.html#footnotes",
    "title": "Forest Data Analysis Report",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://www.opengeodata.nrw.de/produkte/geobasis/hm/3dm_l_las/3dm_l_las/, last visited 7th Dec 2023↩︎\nhttps://github.com/joheisig/GEDIcalibratoR, last visited 7th Dec 2023↩︎"
  },
  {
    "objectID": "appendix/preprocessing.html",
    "href": "appendix/preprocessing.html",
    "title": "",
    "section": "",
    "text": "Load the file with the research areas\n\nsf &lt;- sf::read_sf(here::here(\"research_areas.shp\"))\nprint(sf)\n\nSimple feature collection with 12 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 7.071625 ymin: 51.08151 xmax: 8.539877 ymax: 52.25983\nGeodetic CRS:  WGS 84\n# A tibble: 12 × 4\n      id species name                                                   geometry\n   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;                                             &lt;POLYGON [°]&gt;\n 1     1 oak     rinkerode           ((7.678922 51.85789, 7.675446 51.85752, 7.…\n 2     2 oak     hamm                ((7.858955 51.66699, 7.866444 51.66462, 7.…\n 3     3 oak     muenster            ((7.618908 51.9154, 7.617384 51.9172, 7.61…\n 4     4 pine    greffen             ((8.168691 51.98965, 8.167178 51.99075, 8.…\n 5     5 pine    telgte              ((7.779728 52.00662, 7.781616 52.00662, 7.…\n 6     6 pine    mesum               ((7.534424 52.25499, 7.53378 52.25983, 7.5…\n 7     7 beech   bielefeld_brackwede ((8.524749 51.9921, 8.528418 51.99079, 8.5…\n 8     8 beech   wuelfenrath         ((7.071625 51.29256, 7.072311 51.29334, 7.…\n 9     9 beech   billerbeck          ((7.324729 51.99783, 7.323548 51.99923, 7.…\n10    10 spruce  marienheide         ((7.558102 51.08358, 7.558317 51.08527, 7.…\n11    11 spruce  brilon              ((8.532195 51.41029, 8.535027 51.41064, 8.…\n12    12 spruce  osterwald           ((8.369328 51.21693, 8.371238 51.21718, 8.…\n\n\nInit the project\n\nlibrary(lfa)\nsf::sf_use_s2(FALSE)\nlocations &lt;- lfa_init(\"research_areas.shp\")\n\nDo all of the prprocessing steps\n\nlfa_map_tile_locations(locations,retile,check_flag = \"retile\")\n\nNo further processing: flag retile is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_intersect_areas, ctg = NULL, areas_sf = sf,check_flag = \"intersect\")\n\nNo further processing: flag intersect is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_ground_correction, ctg = NULL,check_flag = \"z_correction\")\n\nNo further processing: flag z_correction is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_segmentation, ctg = NULL,check_flag = \"segmentation\")\n\nNo further processing: flag segmentation is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_detection, catalog = NULL, write_to_file = TRUE,check_flag = \"detection\")\n\nNo further processing: flag detection is set!Function is already computed, no further computings here\n\n\nNULL"
  },
  {
    "objectID": "appendix/preprocessing.html#sec-appendix-preprocessing",
    "href": "appendix/preprocessing.html#sec-appendix-preprocessing",
    "title": "",
    "section": "",
    "text": "Load the file with the research areas\n\nsf &lt;- sf::read_sf(here::here(\"research_areas.shp\"))\nprint(sf)\n\nSimple feature collection with 12 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 7.071625 ymin: 51.08151 xmax: 8.539877 ymax: 52.25983\nGeodetic CRS:  WGS 84\n# A tibble: 12 × 4\n      id species name                                                   geometry\n   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;                                             &lt;POLYGON [°]&gt;\n 1     1 oak     rinkerode           ((7.678922 51.85789, 7.675446 51.85752, 7.…\n 2     2 oak     hamm                ((7.858955 51.66699, 7.866444 51.66462, 7.…\n 3     3 oak     muenster            ((7.618908 51.9154, 7.617384 51.9172, 7.61…\n 4     4 pine    greffen             ((8.168691 51.98965, 8.167178 51.99075, 8.…\n 5     5 pine    telgte              ((7.779728 52.00662, 7.781616 52.00662, 7.…\n 6     6 pine    mesum               ((7.534424 52.25499, 7.53378 52.25983, 7.5…\n 7     7 beech   bielefeld_brackwede ((8.524749 51.9921, 8.528418 51.99079, 8.5…\n 8     8 beech   wuelfenrath         ((7.071625 51.29256, 7.072311 51.29334, 7.…\n 9     9 beech   billerbeck          ((7.324729 51.99783, 7.323548 51.99923, 7.…\n10    10 spruce  marienheide         ((7.558102 51.08358, 7.558317 51.08527, 7.…\n11    11 spruce  brilon              ((8.532195 51.41029, 8.535027 51.41064, 8.…\n12    12 spruce  osterwald           ((8.369328 51.21693, 8.371238 51.21718, 8.…\n\n\nInit the project\n\nlibrary(lfa)\nsf::sf_use_s2(FALSE)\nlocations &lt;- lfa_init(\"research_areas.shp\")\n\nDo all of the prprocessing steps\n\nlfa_map_tile_locations(locations,retile,check_flag = \"retile\")\n\nNo further processing: flag retile is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_intersect_areas, ctg = NULL, areas_sf = sf,check_flag = \"intersect\")\n\nNo further processing: flag intersect is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_ground_correction, ctg = NULL,check_flag = \"z_correction\")\n\nNo further processing: flag z_correction is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_segmentation, ctg = NULL,check_flag = \"segmentation\")\n\nNo further processing: flag segmentation is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_detection, catalog = NULL, write_to_file = TRUE,check_flag = \"detection\")\n\nNo further processing: flag detection is set!Function is already computed, no further computings here\n\n\nNULL"
  },
  {
    "objectID": "methods/preprocessing.html",
    "href": "methods/preprocessing.html",
    "title": "",
    "section": "",
    "text": "In this research study, the management and processing of a large dataset are crucial considerations. The dataset’s substantial size necessitates careful maintenance to ensure efficient handling. Furthermore, the data should be easily processable and editable to facilitate necessary corrections and precalculations within the context of our research objectives. To achieve our goals, we have implemented a framework that automatically derives data based on a shapefile, delineating areas of interest. The processed data and results of precalculations are stored in a straightforward manner to enhance accessibility. Additionally, we have designed functions that establish a user-friendly interface, enabling the execution of algorithms on subsets of the data, such as distinct species. These interfaces are not only directly callable by users but can also be integrated into other functions to automate processes. The overarching aim is to streamline the entire preprocessing workflow using a single script, leveraging only the shapefile as a basis. This subsection details the accomplishments of our R-package in realizing these goals, outlining the preprocessing steps undertaken and justifying their necessity in the context of our research.\nThe data are stored in a data subdirectory of the root directory in the format species/location-name/tile-name. To automate the matching of areas of interest with the catalog from the Land NRW1, we utilize the intersecting tool developed by Heisig2. This tool, allows for the automatic retrieval and placement of data downloaded from the Land NRW catalog. To enhance data accessibility, we have devised an object that incorporates species, location name, and tile name (the NRW internal identifier) for each area This object facilitates the specification of the area to be processed. Additionally, we have defined an initialization function that downloads all tiles, returning a list of tile location objects for subsequent processing. A pivotal component of the package’s preprocessing functionality is the map function, which iterates over a list of tile locations (effectively the entire dataset) and accepts a processing function as an argument. The subsequent paragraph outlines the specific preprocessing steps employed, all of which are implemented within the mapping function.\nTo facilitate memory-handling capabilities, each of the tiles, where one area can span multiple tiles, has been split into manageable chunks. We employed a 50x50m size for each tile, resulting in the division of original 1km x 1km files into 400 tiles. These tiles are stored in our directory structure, with each tile housed in a directory named after its tile name and assigned an id as the filename. Implementation-wise, the lidr::catalog_retile function was instrumental in achieving this segmentation. The resulting smaller chunks allow for efficient iteration during subsequent preprocessing steps.\nThe next phase involves reducing our data to the actual size by intersecting the tiles with the defined area of interest. Using the lidR::merge_spatial function, we intersect the area derived from the shapefile, removing all point cloud items outside this region. Due to our tile-wise approach, empty tiles may arise, and in such cases, those tiles are simply deleted.\nFollowing the size reduction to our dataset, the next step involves correcting the z values. The z values in the data are originally relative to the ellipsoid used for referencing, but we require them to be relative to the ground. To achieve this, we utilize the lidR::tin function, which extrapolates a convex hull between all ground points (classified by the data provider) and calculates the z value based on this structure.\nSubsequently, we aim to perform segmentation for each distinct tree, marking each item of the point cloud with a tree ID. We employ the algorithm described by @li2012, using parameters li2012(dt1 = 2, dt2 = 3, R = 2, Zu = 10, hmin = 5, speed_up = 12). The meanings of these parameters are elucidated in Li et al.’s work [@li2012].\nFinally, the last preprocessing step involves individual tree detection, seeking a single POINT object for each tree. The lidR::lmf function, an implementation of the tree data using a local maximum approach, is utilized for this purpose [@popescu2004]. The results are stored in GeoPackage files within our data structure.\nSee ?@sec-appendix-preprocessing for the implementation of the preprocessing."
  },
  {
    "objectID": "methods/preprocessing.html#preprocessing",
    "href": "methods/preprocessing.html#preprocessing",
    "title": "",
    "section": "",
    "text": "In this research study, the management and processing of a large dataset are crucial considerations. The dataset’s substantial size necessitates careful maintenance to ensure efficient handling. Furthermore, the data should be easily processable and editable to facilitate necessary corrections and precalculations within the context of our research objectives. To achieve our goals, we have implemented a framework that automatically derives data based on a shapefile, delineating areas of interest. The processed data and results of precalculations are stored in a straightforward manner to enhance accessibility. Additionally, we have designed functions that establish a user-friendly interface, enabling the execution of algorithms on subsets of the data, such as distinct species. These interfaces are not only directly callable by users but can also be integrated into other functions to automate processes. The overarching aim is to streamline the entire preprocessing workflow using a single script, leveraging only the shapefile as a basis. This subsection details the accomplishments of our R-package in realizing these goals, outlining the preprocessing steps undertaken and justifying their necessity in the context of our research.\nThe data are stored in a data subdirectory of the root directory in the format species/location-name/tile-name. To automate the matching of areas of interest with the catalog from the Land NRW1, we utilize the intersecting tool developed by Heisig2. This tool, allows for the automatic retrieval and placement of data downloaded from the Land NRW catalog. To enhance data accessibility, we have devised an object that incorporates species, location name, and tile name (the NRW internal identifier) for each area This object facilitates the specification of the area to be processed. Additionally, we have defined an initialization function that downloads all tiles, returning a list of tile location objects for subsequent processing. A pivotal component of the package’s preprocessing functionality is the map function, which iterates over a list of tile locations (effectively the entire dataset) and accepts a processing function as an argument. The subsequent paragraph outlines the specific preprocessing steps employed, all of which are implemented within the mapping function.\nTo facilitate memory-handling capabilities, each of the tiles, where one area can span multiple tiles, has been split into manageable chunks. We employed a 50x50m size for each tile, resulting in the division of original 1km x 1km files into 400 tiles. These tiles are stored in our directory structure, with each tile housed in a directory named after its tile name and assigned an id as the filename. Implementation-wise, the lidr::catalog_retile function was instrumental in achieving this segmentation. The resulting smaller chunks allow for efficient iteration during subsequent preprocessing steps.\nThe next phase involves reducing our data to the actual size by intersecting the tiles with the defined area of interest. Using the lidR::merge_spatial function, we intersect the area derived from the shapefile, removing all point cloud items outside this region. Due to our tile-wise approach, empty tiles may arise, and in such cases, those tiles are simply deleted.\nFollowing the size reduction to our dataset, the next step involves correcting the z values. The z values in the data are originally relative to the ellipsoid used for referencing, but we require them to be relative to the ground. To achieve this, we utilize the lidR::tin function, which extrapolates a convex hull between all ground points (classified by the data provider) and calculates the z value based on this structure.\nSubsequently, we aim to perform segmentation for each distinct tree, marking each item of the point cloud with a tree ID. We employ the algorithm described by @li2012, using parameters li2012(dt1 = 2, dt2 = 3, R = 2, Zu = 10, hmin = 5, speed_up = 12). The meanings of these parameters are elucidated in Li et al.’s work [@li2012].\nFinally, the last preprocessing step involves individual tree detection, seeking a single POINT object for each tree. The lidR::lmf function, an implementation of the tree data using a local maximum approach, is utilized for this purpose [@popescu2004]. The results are stored in GeoPackage files within our data structure.\nSee ?@sec-appendix-preprocessing for the implementation of the preprocessing."
  },
  {
    "objectID": "methods/preprocessing.html#footnotes",
    "href": "methods/preprocessing.html#footnotes",
    "title": "",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://www.opengeodata.nrw.de/produkte/geobasis/hm/3dm_l_las/3dm_l_las/, last visited 7th Dec 2023↩︎\nhttps://github.com/joheisig/GEDIcalibratoR, last visited 7th Dec 2023↩︎"
  }
]