[
  {
    "objectID": "methods/data-aquisition.html",
    "href": "methods/data-aquisition.html",
    "title": "",
    "section": "",
    "text": "This file describing the data acquisition of this project.\nSources for gaining information about the tree species in NRW forests:\n\nWaldmonitor.de [@welle2014]\nDominant tree species by Thuenen: https://atlas.thuenen.de/layers/geonode:Dominant_Species_Class\nValidating with Sentinel RGB imageries the shape and texture of the area:\n\nleaf color\nhuman made /natural shapes of the forest\nHuman made objects in the direct neighboorhoud of the area."
  },
  {
    "objectID": "methods/data-aquisition.html#data-acquisition",
    "href": "methods/data-aquisition.html#data-acquisition",
    "title": "",
    "section": "",
    "text": "This file describing the data acquisition of this project.\nSources for gaining information about the tree species in NRW forests:\n\nWaldmonitor.de [@welle2014]\nDominant tree species by Thuenen: https://atlas.thuenen.de/layers/geonode:Dominant_Species_Class\nValidating with Sentinel RGB imageries the shape and texture of the area:\n\nleaf color\nhuman made /natural shapes of the forest\nHuman made objects in the direct neighboorhoud of the area."
  },
  {
    "objectID": "report.html",
    "href": "report.html",
    "title": "Forest Data Analysis Report",
    "section": "",
    "text": "This report documents the analysis of forest data for different tree species."
  },
  {
    "objectID": "report.html#data-acquisition",
    "href": "report.html#data-acquisition",
    "title": "Forest Data Analysis Report",
    "section": "2.1 Data acquisition",
    "text": "2.1 Data acquisition\nThis file describing the data acquisition of this project.\nSources for gaining information about the tree species in NRW forests:\n\nWaldmonitor.de (Welle et al. 2022)\nDominant tree species by Thuenen: https://atlas.thuenen.de/layers/geonode:Dominant_Species_Class\nValidating with Sentinel RGB imageries the shape and texture of the area:\n\nleaf color\nhuman made /natural shapes of the forest\nHuman made objects in the direct neighboorhoud of the area."
  },
  {
    "objectID": "report.html#preprocessing",
    "href": "report.html#preprocessing",
    "title": "Forest Data Analysis Report",
    "section": "2.2 Preprocessing",
    "text": "2.2 Preprocessing\nIn this research study, the management and processing of a large dataset are crucial considerations. The dataset’s substantial size necessitates careful maintenance to ensure efficient handling. Furthermore, the data should be easily processable and editable to facilitate necessary corrections and precalculations within the context of our research objectives. To achieve our goals, we have implemented a framework that automatically derives data based on a shapefile, delineating areas of interest. The processed data and results of precalculations are stored in a straightforward manner to enhance accessibility. Additionally, we have designed functions that establish a user-friendly interface, enabling the execution of algorithms on subsets of the data, such as distinct species. These interfaces are not only directly callable by users but can also be integrated into other functions to automate processes. The overarching aim is to streamline the entire preprocessing workflow using a single script, leveraging only the shapefile as a basis. This subsection details the accomplishments of our R-package in realizing these goals, outlining the preprocessing steps undertaken and justifying their necessity in the context of our research.\nThe data are stored in a data subdirectory of the root directory in the format species/location-name/tile-name. To automate the matching of areas of interest with the catalog from the Land NRW1, we utilize the intersecting tool developed by Heisig2. This tool, allows for the automatic retrieval and placement of data downloaded from the Land NRW catalog. To enhance data accessibility, we have devised an object that incorporates species, location name, and tile name (the NRW internal identifier) for each area This object facilitates the specification of the area to be processed. Additionally, we have defined an initialization function that downloads all tiles, returning a list of tile location objects for subsequent processing. A pivotal component of the package’s preprocessing functionality is the map function, which iterates over a list of tile locations (effectively the entire dataset) and accepts a processing function as an argument. The subsequent paragraph outlines the specific preprocessing steps employed, all of which are implemented within the mapping function.\nTo facilitate memory-handling capabilities, each of the tiles, where one area can span multiple tiles, has been split into manageable chunks. We employed a 50x50m size for each tile, resulting in the division of original 1km x 1km files into 400 tiles. These tiles are stored in our directory structure, with each tile housed in a directory named after its tile name and assigned an id as the filename. Implementation-wise, the lidr::catalog_retile function was instrumental in achieving this segmentation. The resulting smaller chunks allow for efficient iteration during subsequent preprocessing steps.\nThe next phase involves reducing our data to the actual size by intersecting the tiles with the defined area of interest. Using the lidR::merge_spatial function, we intersect the area derived from the shapefile, removing all point cloud items outside this region. Due to our tile-wise approach, empty tiles may arise, and in such cases, those tiles are simply deleted.\nFollowing the size reduction to our dataset, the next step involves correcting the z values. The z values in the data are originally relative to the ellipsoid used for referencing, but we require them to be relative to the ground. To achieve this, we utilize the lidR::tin function, which extrapolates a convex hull between all ground points (classified by the data provider) and calculates the z value based on this structure.\nSubsequently, we aim to perform segmentation for each distinct tree, marking each item of the point cloud with a tree ID. We employ the algorithm described by Li et al. (2012), using parameters li2012(dt1 = 2, dt2 = 3, R = 2, Zu = 10, hmin = 5, speed_up = 12). The meanings of these parameters are elucidated in Li et al.’s work (Li et al. 2012).\nFinally, the last preprocessing step involves individual tree detection, seeking a single POINT object for each tree. The lidR::lmf function, an implementation of the tree data using a local maximum approach, is utilized for this purpose (Popescu and Wynne 2004). The results are stored in GeoPackage files within our data structure.\nSee Section 5.1 for the implementation of the preprocessing."
  },
  {
    "objectID": "report.html#sec-appendix-preprocessing",
    "href": "report.html#sec-appendix-preprocessing",
    "title": "Forest Data Analysis Report",
    "section": "5.1 Script which can be used to do all preprocessing",
    "text": "5.1 Script which can be used to do all preprocessing\nLoad the file with the research areas ::: {.cell}\nsf &lt;- sf::read_sf(here::here(\"research_areas.shp\"))\nprint(sf)\n\nSimple feature collection with 12 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 7.071625 ymin: 51.08151 xmax: 8.539877 ymax: 52.25983\nGeodetic CRS:  WGS 84\n# A tibble: 12 × 4\n      id species name                                                   geometry\n   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;                                             &lt;POLYGON [°]&gt;\n 1     1 oak     rinkerode           ((7.678922 51.85789, 7.675446 51.85752, 7.…\n 2     2 oak     hamm                ((7.858955 51.66699, 7.866444 51.66462, 7.…\n 3     3 oak     muenster            ((7.618908 51.9154, 7.617384 51.9172, 7.61…\n 4     4 pine    greffen             ((8.168691 51.98965, 8.167178 51.99075, 8.…\n 5     5 pine    telgte              ((7.779728 52.00662, 7.781616 52.00662, 7.…\n 6     6 pine    mesum               ((7.534424 52.25499, 7.53378 52.25983, 7.5…\n 7     7 beech   bielefeld_brackwede ((8.524749 51.9921, 8.528418 51.99079, 8.5…\n 8     8 beech   wuelfenrath         ((7.071625 51.29256, 7.072311 51.29334, 7.…\n 9     9 beech   billerbeck          ((7.324729 51.99783, 7.323548 51.99923, 7.…\n10    10 spruce  marienheide         ((7.558102 51.08358, 7.558317 51.08527, 7.…\n11    11 spruce  brilon              ((8.532195 51.41029, 8.535027 51.41064, 8.…\n12    12 spruce  osterwald           ((8.369328 51.21693, 8.371238 51.21718, 8.…\n\n:::\nInit the project ::: {.cell}\nlibrary(lfa)\nsf::sf_use_s2(FALSE)\nlocations &lt;- lfa_init(\"research_areas.shp\")\n:::\nDo all of the prprocessing steps ::: {.cell}\nlfa_map_tile_locations(locations,retile,check_flag = \"retile\")\n\nNo further processing: flag retile is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_intersect_areas, ctg = NULL, areas_sf = sf,check_flag = \"intersect\")\n\nNo further processing: flag intersect is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_ground_correction, ctg = NULL,check_flag = \"z_correction\")\n\nNo further processing: flag z_correction is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_segmentation, ctg = NULL,check_flag = \"segmentation\")\n\nNo further processing: flag segmentation is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_detection, catalog = NULL, write_to_file = TRUE,check_flag = \"detection\")\n\nNo further processing: flag detection is set!Function is already computed, no further computings here\n\n\nNULL\n\n:::"
  },
  {
    "objectID": "report.html#documentation",
    "href": "report.html#documentation",
    "title": "Forest Data Analysis Report",
    "section": "5.2 Documentation",
    "text": "5.2 Documentation\n\n5.2.1 lfa_capitalize_first_char\nCapitalize First Character of a String\n\nArguments\n\n\n\nArgument\nDescription\n\n\n\n\ninput_string\nA single-character string to be processed.\n\n\n\n\n\nConcept\nString Manipulation\n\n\nDescription\nThis function takes a string as input and returns the same string with the first character capitalized. If the first character is already capitalized, the function does nothing. If the first character is not from the alphabet, an error is thrown.\n\n\nDetails\nThis function performs the following steps:\n\nChecks if the input is a single-character string.\nVerifies if the first character is from the alphabet (A-Z or a-z).\nIf the first character is not already capitalized, it capitalizes it.\nReturns the modified string.\n\n\n\nKeyword\nalphabet\n\n\nNote\nThis function is case-sensitive and assumes ASCII characters.\n\n\nReferences\nNone\n\n\nSeealso\nThis function is related to the basic string manipulation functions in base R.\n\n\nValue\nA modified string with the first character capitalized if it is not already. If the first character is already capitalized, the original string is returned.\n\n\nExamples\n\n# Capitalize the first character of a string\ncapitalize_first_char(\"hello\") # Returns \"Hello\"\ncapitalize_first_char(\"World\") # Returns \"World\"\n\n# Error example (non-alphabetic first character)\ncapitalize_first_char(\"123abc\") # Throws an error\n\n\n\nUsage\n\nlfa_capitalize_first_char(input_string)\n\n\n\n\n5.2.2 lfa_check_flag\nCheck if a flag is set, indicating the completion of a specific process.\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nflag_name\nA character string specifying the name of the flag file. It should be a descriptive and unique identifier for the process being checked.\n\n\n\n\n\nDescription\nThis function checks for the existence of a hidden flag file at a specified location within the working directory. If the flag file is found, a message is printed, and the function returns TRUE to indicate that the associated processing step has already been completed. If the flag file is not found, the function returns FALSE , indicating that further processing can proceed.\n\n\nValue\nA logical value indicating whether the flag is set ( TRUE ) or not ( FALSE ).\n\n\nExamples\n\n# Check if the flag for a process named \"data_processing\" is set\nlfa_check_flag(\"data_processing\")\n\n\n\nUsage\n\nlfa_check_flag(flag_name)\n\n\n\n\n5.2.3 lfa_create_tile_location_objects\nCreate tile location objects\n\nAuthor\nJakob Danel\n\n\nDescription\nThis function traverses a directory structure to find LAZ files and creates tile location objects for each file. The function looks into the the data directory of the repository/working directory. It then creates tile_location objects based on the folder structure. The folder structure should not be touched by hand, but created by lfa_init_data_structure() which builds the structure based on a shape file.\n\n\nSeealso\ntile_location\n\n\nValue\nA vector containing tile location objects.\n\n\nExamples\n\nlfa_create_tile_location_objects()\n\nlfa_create_tile_location_objects()\n\n\n\nUsage\n\nlfa_create_tile_location_objects()\n\n\n\n\n5.2.4 lfa_detection\nPerform tree detection on a lidar catalog and optionally save the results to a file.\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncatalog\nA lidar catalog containing point cloud data. If set to NULL, the function attempts to read the catalog from the specified tile location.\n\n\ntile_location\nAn object specifying the location of the lidar tile. If catalog is NULL, the function attempts to read the catalog from this tile location.\n\n\nwrite_to_file\nA logical value indicating whether to save the detected tree information to a file. Default is TRUE.\n\n\n\n\n\nDescription\nThis function utilizes lidar data to detect trees within a specified catalog. The detected tree information can be optionally saved to a file in the GeoPackage format. The function uses parallel processing to enhance efficiency.\n\n\nValue\nA sf style data frame containing information about the detected trees.\n\n\nExamples\n\n# Perform tree detection on a catalog and save the results to a file\nlfa_detection(catalog = my_catalog, tile_location = my_tile_location, write_to_file = TRUE)\n\n\n\nUsage\n\nlfa_detection(catalog, tile_location, write_to_file = TRUE)\n\n\n\n\n5.2.5 lfa_download_areas\nDownload areas based on spatial features\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nsf_areas\nSpatial features representing areas to be downloaded. It must include columns like “species” “name” See details for more information.\n\n\n\n\n\nAuthor\nJakob Danel\n\n\nDescription\nThis function initiates the data structure and downloads areas based on spatial features.\n\n\nDetails\nThe input data frame, sf_areas , must have the following columns:\n\n“species”: The species associated with the area.\n“name”: The name of the area.\n\nThe function uses the lfa_init_data_structure function to set up the data structure and then iterates through the rows of sf_areas to download each specified area.\n\n\nValue\nNone\n\n\nExamples\n\nlfa_download_areas(sf_areas)\n\n\n# Example spatial features data frame\nsf_areas &lt;- data.frame(\nspecies = c(\"SpeciesA\", \"SpeciesB\"),\nname = c(\"Area1\", \"Area2\"),\n# Must include also other attributes specialized to sf objects\n# such as geometry, for processing of the download\n)\n\nlfa_download_areas(sf_areas)\n\n\n\nUsage\n\nlfa_download_areas(sf_areas)\n\n\n\n\n5.2.6 lfa_download\nDownload an las file from the state NRW from a specific location\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nspecies\nThe species of the tree which is observed at this location\n\n\nname\nThe name of the area that is observed\n\n\nlocation\nAn sf object, which holds the location information for the area where the tile should be downloaded from.\n\n\n\n\n\nDescription\nIt will download the file and save it to data/ list(list(“html”), list(list(“”))) / list(list(“html”), list(list(“”))) with the name of the tile\n\n\nValue\nThe LASCatalog object of the downloaded file\n\n\nUsage\n\nlfa_download(species, name, location)\n\n\n\n\n5.2.7 lfa_get_flag_path\nGet the path to a flag file indicating the completion of a specific process.\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nflag_name\nA character string specifying the name of the flag file. It should be a descriptive and unique identifier for the process being flagged.\n\n\n\n\n\nDescription\nThis function constructs and returns the path to a hidden flag file, which serves as an indicator that a particular processing step has been completed. The flag file is created in a designated location within the working directory.\n\n\nValue\nA character string representing the absolute path to the hidden flag file.\n\n\nExamples\n\n# Get the flag path for a process named \"data_processing\"\nlfa_get_flag_path(\"data_processing\")\n\n\n\nUsage\n\nlfa_get_flag_path(flag_name)\n\n\n\n\n5.2.8 lfa_ground_correction\nCorrect the point clouds for correct ground imagery\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nctg\nAn LASCatalog object. If not null, it will perform the actions on this object, if NULL inferring the catalog from the tile_location\n\n\ntile_location\nA tile_location type object holding the information about the location of the cataog. This is used to save the catalog after processing too.\n\n\n\n\n\nAuthor\nJakob Danel\n\n\nDescription\nThis function is needed to correct the Z value of the point cloud, relative to the real ground height. After using this function to your catalog, the Z values can be seen as the real elevation about the ground. At the moment the function uses the tin() function from the lidr package. NOTE : The operation is inplace and can not be reverted, the old values of the point cloud will be deleted!\n\n\nValue\nA catalog with the corrected z values. The catalog is always stored at tile_location and holding only the transformed values.\n\n\nUsage\n\nlfa_ground_correction(ctg, tile_location)\n\n\n\n\n5.2.9 lfa_init_data_structure\nInitialize data structure for species and areas\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nsf_species\nA data frame with information about species and associated areas.\n\n\n\n\n\nDescription\nThis function initializes the data structure for storing species and associated areas.\n\n\nDetails\nThe input data frame, sf_species , should have at least the following columns:\n\n“species”: The names of the species for which the data structure needs to be initialized.\n“name”: The names of the associated areas.\n\nThe function creates directories based on the species and area information provided in the sf_species data frame. It checks whether the directories already exist and creates them if they don’t.\n\n\nValue\nNone\n\n\nExamples\n\n# Example species data frame\nsf_species &lt;- data.frame(\nspecies = c(\"SpeciesA\", \"SpeciesB\"),\nname = c(\"Area1\", \"Area2\"),\n# Other necessary columns\n)\n\nlfa_init_data_structure(sf_species)\n\n# Example species data frame\nsf_species &lt;- data.frame(\nspecies = c(\"SpeciesA\", \"SpeciesB\"),\nname = c(\"Area1\", \"Area2\"),\n# Other necessary columns\n)\n\nlfa_init_data_structure(sf_species)\n\n\n\nUsage\n\nlfa_init_data_structure(sf_species)\n\n\n\n\n5.2.10 lfa_init\nInitialize LFA (LiDAR forest analysis) data processing\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nsf_file\nA character string specifying the path to the shapefile containing spatial features of research areas.\n\n\n\n\n\nDescription\nThis function initializes the LFA data processing by reading a shapefile containing spatial features of research areas, downloading the specified areas, and creating tile location objects for each area.\n\n\nDetails\nThis function reads a shapefile ( sf_file ) using the sf package, which should contain information about research areas. It then calls the lfa_download_areas function to download the specified areas and lfa_create_tile_location_objects to create tile location objects based on Lidar data files in those areas. The shapefile MUST follow the following requirements:\n\nEach geometry must be a single object of type polygon\nEach entry must have the following attributes:\nspecies: A string describing the tree species of the area.\nname: A string describing the location of the area.\n\n\n\nValue\nA vector containing tile location objects.\n\n\nExamples\n\n# Initialize LFA processing with the default shapefile\nlfa_init()\n\n# Initialize LFA processing with a custom shapefile\nlfa_init(\"custom_areas.shp\")\n\n# Example usage with the default shapefile\nlfa_init()\n\n# Example usage with a custom shapefile\nlfa_init(\"custom_areas.shp\")\n\n\n\nUsage\n\nlfa_init(sf_file = \"research_areas.shp\")\n\n\n\n\n5.2.11 lfa_intersect_areas\nIntersect Lidar Catalog with Spatial Features\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nctg\nA LAScatalog object representing the Lidar data to be processed.\n\n\ntile_location\nA tile location object representing the specific area of interest.\n\n\nareas_sf\nSpatial features defining areas.\n\n\n\n\n\nDescription\nThis function intersects a Lidar catalog with a specific area defined by spatial features.\n\n\nDetails\nThe function intersects the Lidar catalog specified by ctg with a specific area defined by the tile_location object and areas_sf . It removes points outside the specified area and returns a modified LAScatalog object.\nThe specified area is identified based on the species and name attributes in the tile_location object. If a matching area is not found in areas_sf , the function stops with an error.\nThe function then transforms the spatial reference of the identified area to match that of the Lidar catalog using sf::st_transform .\nThe processing is applied to each chunk in the catalog using the identify_area function, which merges spatial information and filters out points that are not classified as inside the identified area. After processing, the function writes the modified LAS files back to the original file locations, removing points outside the specified area.\nIf an error occurs during the processing of a chunk, a warning is issued, and the function continues processing the next chunks. If no points are found after filtering, a warning is issued, and NULL is returned.\n\n\nSeealso\nOther functions in the Lidar forest analysis (LFA) package.\n\n\nValue\nA modified LAScatalog object with points outside the specified area removed.\n\n\nExamples\n\n# Example usage\nlfa_intersect_areas(ctg, tile_location, areas_sf)\n\n# Example usage\nlfa_intersect_areas(ctg, tile_location, areas_sf)\n\n\n\nUsage\n\nlfa_intersect_areas(ctg, tile_location, areas_sf)\n\n\n\n\n5.2.12 lfa_load_ctg_if_not_present\nLoading the catalog if it is not present\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nctg\nCatalog object. Can be NULL\n\n\ntile_location\nThe location to look for the catalog tiles, if their are not present\n\n\n\n\n\nDescription\nThis function checks if the catalog is NULL . If it is it will load the catalog from the tile_location\n\n\nValue\nThe provided ctg object if not null, else the catalog for the tiles of the tile_location.\n\n\nUsage\n\nlfa_load_ctg_if_not_present(ctg, tile_location)\n\n\n\n\n5.2.13 lfa_map_tile_locations\nMap Function Over Tile Locations\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntile_locations\nA list of tile location objects.\n\n\nmap_function\nThe mapping function to be applied to each tile location.\n\n\n...\nAdditional arguments to be passed to the mapping function.\n\n\n\n\n\nDescription\nThis function applies a specified mapping function to each tile location in a list.\n\n\nDetails\nThis function iterates over each tile location in the provided list ( tile_locations ) and applies the specified mapping function ( map_function ) to each tile location. The mapping function should accept a tile location object as its first argument, and additional arguments can be passed using the ellipsis ( ... ) syntax.\nThis function is useful for performing operations on multiple tile locations concurrently, such as loading Lidar data, processing areas, or other tasks that involve tile locations.\n\n\nSeealso\nThe mapping function provided should be compatible with the structure and requirements of the tile locations and the specific task being performed.\n\n\nValue\nNone\n\n\nExamples\n\n# Example usage\nlfa_map_tile_locations(tile_locations, my_mapping_function, param1 = \"value\")\n\n# Example usage\nlfa_map_tile_locations(tile_locations, my_mapping_function, param1 = \"value\")\n\n\n\nUsage\n\nlfa_map_tile_locations(tile_locations, map_function, check_flag = NULL, ...)\n\n\n\n\n5.2.14 lfa_merge_and_save\nMerge and Save Text Files in a Directory\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninput_directory\nThe path to the input directory containing text files.\n\n\noutput_name\nThe name for the output file where the merged content will be saved.\n\n\n\n\n\nDescription\nThis function takes an input directory and an output name as arguments. It merges the textual content of all files in the specified directory into a single string, with each file’s content separated by a newline character. The merged content is then saved into a file named after the output name in the same directory. After the merging is complete, all input files are deleted.\n\n\nDetails\nThis function reads the content of each text file in the specified input directory and concatenates them into a single string. Each file’s content is separated by a newline character. The merged content is then saved into a file named after the output name in the same directory. Finally, all input files are deleted from the directory.\n\n\nSeealso\nreadLines , writeLines , file.remove\n\n\nValue\nThis function does not explicitly return any value. It prints a message indicating the successful completion of the merging and saving process.\n\n\nExamples\n\n# Merge text files in the \"data_files\" directory and save the result in \"merged_output\"\nlfa_merge_and_save(\"data_files\", \"merged_output\")\n\n# Merge text files in the \"data_files\" directory and save the result in \"merged_output\"\nlfa_merge_and_save(\"data_files\", \"merged_output\")\n\n\n\nUsage\n\nlfa_merge_and_save(input_directory, output_name)\n\n\n\n\n5.2.15 lfa_rd_to_qmd\nConvert Rd File to Markdown\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nrdfile\nThe path to the Rd file or a parsed Rd object.\n\n\noutfile\nThe path to the output Markdown file (including the file extension).\n\n\nappend\nLogical, indicating whether to append to an existing file (default is FALSE).\n\n\n\n\n\nDescription\nIMPORTANT NOTE: This function is nearly identical to the Rd2md::Rd2markdown function from the Rd2md package. We needed to implement our own version of it because of various reasons:\n\nThe algorithm uses hardcoded header sizes (h1 and h2 in original) which is not feasible for our use-case of the markdown.\nWe needed to add some Quarto Markdown specifics, e.g. to make sure that the examples will not be runned.\nWe want to exclude certain tags from our implementation.\n\n\n\nDetails\nFor that reason we copied the method and made changes as needed and also added this custom documentation.\nThis function converts an Rd (R documentation) file to Markdown format (.md) and saves the converted file at the specified location. The function allows appending to an existing file or creating a new one. The resulting Markdown file includes sections for the function’s name, title, and additional content such as examples, usage, arguments, and other sections present in the Rd file.\nThe function performs the following steps:\n\nParses the Rd file using the Rd2md package.\nCreates a Markdown file with sections for the function’s name, title, and additional content.\nAppends the content to an existing file if append is set to TRUE.\nSaves the resulting Markdown file at the specified location.\n\n\n\nSeealso\nRd2md::parseRd\n\n\nValue\nThis function does not explicitly return any value. It saves the converted Markdown file at the specified location as described in the details section.\n\n\nExamples\n\n# Convert Rd file to Markdown and save it\nlfa_rd_to_md(\"path/to/your/file.Rd\", \"path/to/your/output/file.md\")\n\n# Convert Rd file to Markdown and append to an existing file\nlfa_rd_to_md(\"path/to/your/file.Rd\", \"path/to/existing/output/file.md\", append = TRUE)\n\n\n\nUsage\n\nlfa_rd_to_qmd(rdfile, outfile, append = FALSE)\n\n\n\n\n5.2.16 lfa_rd_to_results\nConvert Rd Files to Markdown and Merge Results\n\nDescription\nThis function converts all Rd (R documentation) files in the “man” directory to Markdown format (.qmd) and saves the converted files in the “results/appendix/package-docs” directory. It then merges the converted Markdown files into a single string and saves the merged content into a file named “docs.qmd” in the “results/appendix/package-docs” directory.\n\n\nDetails\nThe function performs the following steps:\n\nRemoves any existing “docs.qmd” file in the “results/appendix/package-docs” directory.\nFinds all Rd files in the “man” directory.\nConverts each Rd file to Markdown format (.qmd) using the lfa_rd_to_qmd function.\nSaves the converted Markdown files in the “results/appendix/package-docs” directory.\nMerges the content of all converted Markdown files into a single string.\nSaves the merged content into a file named “docs.qmd” in the “results/appendix/package-docs” directory.\n\n\n\nSeealso\nlfa_rd_to_qmd , lfa_merge_and_save\n\n\nValue\nThis function does not explicitly return any value. It performs the conversion, merging, and saving operations as described in the details section.\n\n\nExamples\n\n# Convert Rd files to Markdown and merge the results\nlfa_rd_to_results()\n\n\n\nUsage\n\nlfa_rd_to_results()\n\n\n\n\n5.2.17 lfa_segmentation\nSegment the elements of an point cloud by trees\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nctg\nAn LASCatalog object. If not null, it will perform the actions on this object, if NULL inferring the catalog from the tile_location\n\n\ntile_location\nA tile_location type object holding the information about the location of the catalog. This is used to save the catalog after processing too.\n\n\n\n\n\nAuthor\nJakob Danel\n\n\nDescription\nThis function will try to to divide the hole point cloud into unique trees. Therefore it is assigning for each chunk of the catalog a treeID for each point. Therefore the algorithm uses the li2012 implementation with the following parameters: li2012(dt1 = 2, dt2 = 3, R = 2, Zu = 10, hmin = 5, speed_up = 12) NOTE : The operation is in place and can not be reverted, the old values of the point cloud will be deleted!\n\n\nValue\nA catalog where each chunk has additional treeID values indicating the belonging tree.\n\n\nUsage\n\nlfa_segmentation(ctg, tile_location)\n\n\n\n\n5.2.18 lfa_set_flag\nSet a flag to indicate the completion of a specific process.\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nflag_name\nA character string specifying the name of the flag file. It should be a descriptive and unique identifier for the process being flagged.\n\n\n\n\n\nDescription\nThis function creates a hidden flag file at a specified location within the working directory to indicate that a particular processing step has been completed. If the flag file already exists, a warning is issued.\n\n\nValue\nThis function does not have a formal return value.\n\n\nExamples\n\n# Set the flag for a process named \"data_processing\"\nlfa_set_flag(\"data_processing\")\n\n\n\nUsage\n\nlfa_set_flag(flag_name)"
  },
  {
    "objectID": "report.html#footnotes",
    "href": "report.html#footnotes",
    "title": "Forest Data Analysis Report",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://www.opengeodata.nrw.de/produkte/geobasis/hm/3dm_l_las/3dm_l_las/, last visited 7th Dec 2023↩︎\nhttps://github.com/joheisig/GEDIcalibratoR, last visited 7th Dec 2023↩︎"
  },
  {
    "objectID": "appendix/preprocessing.html",
    "href": "appendix/preprocessing.html",
    "title": "",
    "section": "",
    "text": "Load the file with the research areas\n\nsf &lt;- sf::read_sf(here::here(\"research_areas.shp\"))\nprint(sf)\n\nSimple feature collection with 12 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 7.071625 ymin: 51.08151 xmax: 8.539877 ymax: 52.25983\nGeodetic CRS:  WGS 84\n# A tibble: 12 × 4\n      id species name                                                   geometry\n   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;                                             &lt;POLYGON [°]&gt;\n 1     1 oak     rinkerode           ((7.678922 51.85789, 7.675446 51.85752, 7.…\n 2     2 oak     hamm                ((7.858955 51.66699, 7.866444 51.66462, 7.…\n 3     3 oak     muenster            ((7.618908 51.9154, 7.617384 51.9172, 7.61…\n 4     4 pine    greffen             ((8.168691 51.98965, 8.167178 51.99075, 8.…\n 5     5 pine    telgte              ((7.779728 52.00662, 7.781616 52.00662, 7.…\n 6     6 pine    mesum               ((7.534424 52.25499, 7.53378 52.25983, 7.5…\n 7     7 beech   bielefeld_brackwede ((8.524749 51.9921, 8.528418 51.99079, 8.5…\n 8     8 beech   wuelfenrath         ((7.071625 51.29256, 7.072311 51.29334, 7.…\n 9     9 beech   billerbeck          ((7.324729 51.99783, 7.323548 51.99923, 7.…\n10    10 spruce  marienheide         ((7.558102 51.08358, 7.558317 51.08527, 7.…\n11    11 spruce  brilon              ((8.532195 51.41029, 8.535027 51.41064, 8.…\n12    12 spruce  osterwald           ((8.369328 51.21693, 8.371238 51.21718, 8.…\n\n\nInit the project\n\nlibrary(lfa)\nsf::sf_use_s2(FALSE)\nlocations &lt;- lfa_init(\"research_areas.shp\")\n\nDo all of the prprocessing steps\n\nlfa_map_tile_locations(locations,retile,check_flag = \"retile\")\n\nNo further processing: flag retile is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_intersect_areas, ctg = NULL, areas_sf = sf,check_flag = \"intersect\")\n\nNo further processing: flag intersect is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_ground_correction, ctg = NULL,check_flag = \"z_correction\")\n\nNo further processing: flag z_correction is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_segmentation, ctg = NULL,check_flag = \"segmentation\")\n\nNo further processing: flag segmentation is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_detection, catalog = NULL, write_to_file = TRUE,check_flag = \"detection\")\n\nNo further processing: flag detection is set!Function is already computed, no further computings here\n\n\nNULL"
  },
  {
    "objectID": "appendix/preprocessing.html#sec-appendix-preprocessing",
    "href": "appendix/preprocessing.html#sec-appendix-preprocessing",
    "title": "",
    "section": "",
    "text": "Load the file with the research areas\n\nsf &lt;- sf::read_sf(here::here(\"research_areas.shp\"))\nprint(sf)\n\nSimple feature collection with 12 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 7.071625 ymin: 51.08151 xmax: 8.539877 ymax: 52.25983\nGeodetic CRS:  WGS 84\n# A tibble: 12 × 4\n      id species name                                                   geometry\n   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;                                             &lt;POLYGON [°]&gt;\n 1     1 oak     rinkerode           ((7.678922 51.85789, 7.675446 51.85752, 7.…\n 2     2 oak     hamm                ((7.858955 51.66699, 7.866444 51.66462, 7.…\n 3     3 oak     muenster            ((7.618908 51.9154, 7.617384 51.9172, 7.61…\n 4     4 pine    greffen             ((8.168691 51.98965, 8.167178 51.99075, 8.…\n 5     5 pine    telgte              ((7.779728 52.00662, 7.781616 52.00662, 7.…\n 6     6 pine    mesum               ((7.534424 52.25499, 7.53378 52.25983, 7.5…\n 7     7 beech   bielefeld_brackwede ((8.524749 51.9921, 8.528418 51.99079, 8.5…\n 8     8 beech   wuelfenrath         ((7.071625 51.29256, 7.072311 51.29334, 7.…\n 9     9 beech   billerbeck          ((7.324729 51.99783, 7.323548 51.99923, 7.…\n10    10 spruce  marienheide         ((7.558102 51.08358, 7.558317 51.08527, 7.…\n11    11 spruce  brilon              ((8.532195 51.41029, 8.535027 51.41064, 8.…\n12    12 spruce  osterwald           ((8.369328 51.21693, 8.371238 51.21718, 8.…\n\n\nInit the project\n\nlibrary(lfa)\nsf::sf_use_s2(FALSE)\nlocations &lt;- lfa_init(\"research_areas.shp\")\n\nDo all of the prprocessing steps\n\nlfa_map_tile_locations(locations,retile,check_flag = \"retile\")\n\nNo further processing: flag retile is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_intersect_areas, ctg = NULL, areas_sf = sf,check_flag = \"intersect\")\n\nNo further processing: flag intersect is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_ground_correction, ctg = NULL,check_flag = \"z_correction\")\n\nNo further processing: flag z_correction is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_segmentation, ctg = NULL,check_flag = \"segmentation\")\n\nNo further processing: flag segmentation is set!Function is already computed, no further computings here\n\n\nNULL\n\nlfa_map_tile_locations(locations, lfa_detection, catalog = NULL, write_to_file = TRUE,check_flag = \"detection\")\n\nNo further processing: flag detection is set!Function is already computed, no further computings here\n\n\nNULL"
  },
  {
    "objectID": "appendix/package-docs/docs.html",
    "href": "appendix/package-docs/docs.html",
    "title": "",
    "section": "",
    "text": "lfa_capitalize_first_char\nCapitalize First Character of a String\n\nArguments\n\n\n\nArgument\nDescription\n\n\n\n\ninput_string\nA single-character string to be processed.\n\n\n\n\n\nConcept\nString Manipulation\n\n\nDescription\nThis function takes a string as input and returns the same string with the first character capitalized. If the first character is already capitalized, the function does nothing. If the first character is not from the alphabet, an error is thrown.\n\n\nDetails\nThis function performs the following steps:\n\nChecks if the input is a single-character string.\nVerifies if the first character is from the alphabet (A-Z or a-z).\nIf the first character is not already capitalized, it capitalizes it.\nReturns the modified string.\n\n\n\nKeyword\nalphabet\n\n\nNote\nThis function is case-sensitive and assumes ASCII characters.\n\n\nReferences\nNone\n\n\nSeealso\nThis function is related to the basic string manipulation functions in base R.\n\n\nValue\nA modified string with the first character capitalized if it is not already. If the first character is already capitalized, the original string is returned.\n\n\nExamples\n\n# Capitalize the first character of a string\ncapitalize_first_char(\"hello\") # Returns \"Hello\"\ncapitalize_first_char(\"World\") # Returns \"World\"\n\n# Error example (non-alphabetic first character)\ncapitalize_first_char(\"123abc\") # Throws an error\n\n\n\nUsage\n\nlfa_capitalize_first_char(input_string)\n\n\n\n\nlfa_check_flag\nCheck if a flag is set, indicating the completion of a specific process.\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nflag_name\nA character string specifying the name of the flag file. It should be a descriptive and unique identifier for the process being checked.\n\n\n\n\n\nDescription\nThis function checks for the existence of a hidden flag file at a specified location within the working directory. If the flag file is found, a message is printed, and the function returns TRUE to indicate that the associated processing step has already been completed. If the flag file is not found, the function returns FALSE , indicating that further processing can proceed.\n\n\nValue\nA logical value indicating whether the flag is set ( TRUE ) or not ( FALSE ).\n\n\nExamples\n\n# Check if the flag for a process named \"data_processing\" is set\nlfa_check_flag(\"data_processing\")\n\n\n\nUsage\n\nlfa_check_flag(flag_name)\n\n\n\n\nlfa_create_tile_location_objects\nCreate tile location objects\n\nAuthor\nJakob Danel\n\n\nDescription\nThis function traverses a directory structure to find LAZ files and creates tile location objects for each file. The function looks into the the data directory of the repository/working directory. It then creates tile_location objects based on the folder structure. The folder structure should not be touched by hand, but created by lfa_init_data_structure() which builds the structure based on a shape file.\n\n\nSeealso\ntile_location\n\n\nValue\nA vector containing tile location objects.\n\n\nExamples\n\nlfa_create_tile_location_objects()\n\nlfa_create_tile_location_objects()\n\n\n\nUsage\n\nlfa_create_tile_location_objects()\n\n\n\n\nlfa_detection\nPerform tree detection on a lidar catalog and optionally save the results to a file.\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ncatalog\nA lidar catalog containing point cloud data. If set to NULL, the function attempts to read the catalog from the specified tile location.\n\n\ntile_location\nAn object specifying the location of the lidar tile. If catalog is NULL, the function attempts to read the catalog from this tile location.\n\n\nwrite_to_file\nA logical value indicating whether to save the detected tree information to a file. Default is TRUE.\n\n\n\n\n\nDescription\nThis function utilizes lidar data to detect trees within a specified catalog. The detected tree information can be optionally saved to a file in the GeoPackage format. The function uses parallel processing to enhance efficiency.\n\n\nValue\nA sf style data frame containing information about the detected trees.\n\n\nExamples\n\n# Perform tree detection on a catalog and save the results to a file\nlfa_detection(catalog = my_catalog, tile_location = my_tile_location, write_to_file = TRUE)\n\n\n\nUsage\n\nlfa_detection(catalog, tile_location, write_to_file = TRUE)\n\n\n\n\nlfa_download_areas\nDownload areas based on spatial features\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nsf_areas\nSpatial features representing areas to be downloaded. It must include columns like “species” “name” See details for more information.\n\n\n\n\n\nAuthor\nJakob Danel\n\n\nDescription\nThis function initiates the data structure and downloads areas based on spatial features.\n\n\nDetails\nThe input data frame, sf_areas , must have the following columns:\n\n“species”: The species associated with the area.\n“name”: The name of the area.\n\nThe function uses the lfa_init_data_structure function to set up the data structure and then iterates through the rows of sf_areas to download each specified area.\n\n\nValue\nNone\n\n\nExamples\n\nlfa_download_areas(sf_areas)\n\n\n# Example spatial features data frame\nsf_areas &lt;- data.frame(\nspecies = c(\"SpeciesA\", \"SpeciesB\"),\nname = c(\"Area1\", \"Area2\"),\n# Must include also other attributes specialized to sf objects\n# such as geometry, for processing of the download\n)\n\nlfa_download_areas(sf_areas)\n\n\n\nUsage\n\nlfa_download_areas(sf_areas)\n\n\n\n\nlfa_download\nDownload an las file from the state NRW from a specific location\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nspecies\nThe species of the tree which is observed at this location\n\n\nname\nThe name of the area that is observed\n\n\nlocation\nAn sf object, which holds the location information for the area where the tile should be downloaded from.\n\n\n\n\n\nDescription\nIt will download the file and save it to data/ list(list(“html”), list(list(“”))) / list(list(“html”), list(list(“”))) with the name of the tile\n\n\nValue\nThe LASCatalog object of the downloaded file\n\n\nUsage\n\nlfa_download(species, name, location)\n\n\n\n\nlfa_get_flag_path\nGet the path to a flag file indicating the completion of a specific process.\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nflag_name\nA character string specifying the name of the flag file. It should be a descriptive and unique identifier for the process being flagged.\n\n\n\n\n\nDescription\nThis function constructs and returns the path to a hidden flag file, which serves as an indicator that a particular processing step has been completed. The flag file is created in a designated location within the working directory.\n\n\nValue\nA character string representing the absolute path to the hidden flag file.\n\n\nExamples\n\n# Get the flag path for a process named \"data_processing\"\nlfa_get_flag_path(\"data_processing\")\n\n\n\nUsage\n\nlfa_get_flag_path(flag_name)\n\n\n\n\nlfa_ground_correction\nCorrect the point clouds for correct ground imagery\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nctg\nAn LASCatalog object. If not null, it will perform the actions on this object, if NULL inferring the catalog from the tile_location\n\n\ntile_location\nA tile_location type object holding the information about the location of the cataog. This is used to save the catalog after processing too.\n\n\n\n\n\nAuthor\nJakob Danel\n\n\nDescription\nThis function is needed to correct the Z value of the point cloud, relative to the real ground height. After using this function to your catalog, the Z values can be seen as the real elevation about the ground. At the moment the function uses the tin() function from the lidr package. NOTE : The operation is inplace and can not be reverted, the old values of the point cloud will be deleted!\n\n\nValue\nA catalog with the corrected z values. The catalog is always stored at tile_location and holding only the transformed values.\n\n\nUsage\n\nlfa_ground_correction(ctg, tile_location)\n\n\n\n\nlfa_init_data_structure\nInitialize data structure for species and areas\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nsf_species\nA data frame with information about species and associated areas.\n\n\n\n\n\nDescription\nThis function initializes the data structure for storing species and associated areas.\n\n\nDetails\nThe input data frame, sf_species , should have at least the following columns:\n\n“species”: The names of the species for which the data structure needs to be initialized.\n“name”: The names of the associated areas.\n\nThe function creates directories based on the species and area information provided in the sf_species data frame. It checks whether the directories already exist and creates them if they don’t.\n\n\nValue\nNone\n\n\nExamples\n\n# Example species data frame\nsf_species &lt;- data.frame(\nspecies = c(\"SpeciesA\", \"SpeciesB\"),\nname = c(\"Area1\", \"Area2\"),\n# Other necessary columns\n)\n\nlfa_init_data_structure(sf_species)\n\n# Example species data frame\nsf_species &lt;- data.frame(\nspecies = c(\"SpeciesA\", \"SpeciesB\"),\nname = c(\"Area1\", \"Area2\"),\n# Other necessary columns\n)\n\nlfa_init_data_structure(sf_species)\n\n\n\nUsage\n\nlfa_init_data_structure(sf_species)\n\n\n\n\nlfa_init\nInitialize LFA (LiDAR forest analysis) data processing\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nsf_file\nA character string specifying the path to the shapefile containing spatial features of research areas.\n\n\n\n\n\nDescription\nThis function initializes the LFA data processing by reading a shapefile containing spatial features of research areas, downloading the specified areas, and creating tile location objects for each area.\n\n\nDetails\nThis function reads a shapefile ( sf_file ) using the sf package, which should contain information about research areas. It then calls the lfa_download_areas function to download the specified areas and lfa_create_tile_location_objects to create tile location objects based on Lidar data files in those areas. The shapefile MUST follow the following requirements:\n\nEach geometry must be a single object of type polygon\nEach entry must have the following attributes:\nspecies: A string describing the tree species of the area.\nname: A string describing the location of the area.\n\n\n\nValue\nA vector containing tile location objects.\n\n\nExamples\n\n# Initialize LFA processing with the default shapefile\nlfa_init()\n\n# Initialize LFA processing with a custom shapefile\nlfa_init(\"custom_areas.shp\")\n\n# Example usage with the default shapefile\nlfa_init()\n\n# Example usage with a custom shapefile\nlfa_init(\"custom_areas.shp\")\n\n\n\nUsage\n\nlfa_init(sf_file = \"research_areas.shp\")\n\n\n\n\nlfa_intersect_areas\nIntersect Lidar Catalog with Spatial Features\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nctg\nA LAScatalog object representing the Lidar data to be processed.\n\n\ntile_location\nA tile location object representing the specific area of interest.\n\n\nareas_sf\nSpatial features defining areas.\n\n\n\n\n\nDescription\nThis function intersects a Lidar catalog with a specific area defined by spatial features.\n\n\nDetails\nThe function intersects the Lidar catalog specified by ctg with a specific area defined by the tile_location object and areas_sf . It removes points outside the specified area and returns a modified LAScatalog object.\nThe specified area is identified based on the species and name attributes in the tile_location object. If a matching area is not found in areas_sf , the function stops with an error.\nThe function then transforms the spatial reference of the identified area to match that of the Lidar catalog using sf::st_transform .\nThe processing is applied to each chunk in the catalog using the identify_area function, which merges spatial information and filters out points that are not classified as inside the identified area. After processing, the function writes the modified LAS files back to the original file locations, removing points outside the specified area.\nIf an error occurs during the processing of a chunk, a warning is issued, and the function continues processing the next chunks. If no points are found after filtering, a warning is issued, and NULL is returned.\n\n\nSeealso\nOther functions in the Lidar forest analysis (LFA) package.\n\n\nValue\nA modified LAScatalog object with points outside the specified area removed.\n\n\nExamples\n\n# Example usage\nlfa_intersect_areas(ctg, tile_location, areas_sf)\n\n# Example usage\nlfa_intersect_areas(ctg, tile_location, areas_sf)\n\n\n\nUsage\n\nlfa_intersect_areas(ctg, tile_location, areas_sf)\n\n\n\n\nlfa_load_ctg_if_not_present\nLoading the catalog if it is not present\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nctg\nCatalog object. Can be NULL\n\n\ntile_location\nThe location to look for the catalog tiles, if their are not present\n\n\n\n\n\nDescription\nThis function checks if the catalog is NULL . If it is it will load the catalog from the tile_location\n\n\nValue\nThe provided ctg object if not null, else the catalog for the tiles of the tile_location.\n\n\nUsage\n\nlfa_load_ctg_if_not_present(ctg, tile_location)\n\n\n\n\nlfa_map_tile_locations\nMap Function Over Tile Locations\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ntile_locations\nA list of tile location objects.\n\n\nmap_function\nThe mapping function to be applied to each tile location.\n\n\n...\nAdditional arguments to be passed to the mapping function.\n\n\n\n\n\nDescription\nThis function applies a specified mapping function to each tile location in a list.\n\n\nDetails\nThis function iterates over each tile location in the provided list ( tile_locations ) and applies the specified mapping function ( map_function ) to each tile location. The mapping function should accept a tile location object as its first argument, and additional arguments can be passed using the ellipsis ( ... ) syntax.\nThis function is useful for performing operations on multiple tile locations concurrently, such as loading Lidar data, processing areas, or other tasks that involve tile locations.\n\n\nSeealso\nThe mapping function provided should be compatible with the structure and requirements of the tile locations and the specific task being performed.\n\n\nValue\nNone\n\n\nExamples\n\n# Example usage\nlfa_map_tile_locations(tile_locations, my_mapping_function, param1 = \"value\")\n\n# Example usage\nlfa_map_tile_locations(tile_locations, my_mapping_function, param1 = \"value\")\n\n\n\nUsage\n\nlfa_map_tile_locations(tile_locations, map_function, check_flag = NULL, ...)\n\n\n\n\nlfa_merge_and_save\nMerge and Save Text Files in a Directory\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\ninput_directory\nThe path to the input directory containing text files.\n\n\noutput_name\nThe name for the output file where the merged content will be saved.\n\n\n\n\n\nDescription\nThis function takes an input directory and an output name as arguments. It merges the textual content of all files in the specified directory into a single string, with each file’s content separated by a newline character. The merged content is then saved into a file named after the output name in the same directory. After the merging is complete, all input files are deleted.\n\n\nDetails\nThis function reads the content of each text file in the specified input directory and concatenates them into a single string. Each file’s content is separated by a newline character. The merged content is then saved into a file named after the output name in the same directory. Finally, all input files are deleted from the directory.\n\n\nSeealso\nreadLines , writeLines , file.remove\n\n\nValue\nThis function does not explicitly return any value. It prints a message indicating the successful completion of the merging and saving process.\n\n\nExamples\n\n# Merge text files in the \"data_files\" directory and save the result in \"merged_output\"\nlfa_merge_and_save(\"data_files\", \"merged_output\")\n\n# Merge text files in the \"data_files\" directory and save the result in \"merged_output\"\nlfa_merge_and_save(\"data_files\", \"merged_output\")\n\n\n\nUsage\n\nlfa_merge_and_save(input_directory, output_name)\n\n\n\n\nlfa_rd_to_qmd\nConvert Rd File to Markdown\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nrdfile\nThe path to the Rd file or a parsed Rd object.\n\n\noutfile\nThe path to the output Markdown file (including the file extension).\n\n\nappend\nLogical, indicating whether to append to an existing file (default is FALSE).\n\n\n\n\n\nDescription\nIMPORTANT NOTE: This function is nearly identical to the Rd2md::Rd2markdown function from the Rd2md package. We needed to implement our own version of it because of various reasons:\n\nThe algorithm uses hardcoded header sizes (h1 and h2 in original) which is not feasible for our use-case of the markdown.\nWe needed to add some Quarto Markdown specifics, e.g. to make sure that the examples will not be runned.\nWe want to exclude certain tags from our implementation.\n\n\n\nDetails\nFor that reason we copied the method and made changes as needed and also added this custom documentation.\nThis function converts an Rd (R documentation) file to Markdown format (.md) and saves the converted file at the specified location. The function allows appending to an existing file or creating a new one. The resulting Markdown file includes sections for the function’s name, title, and additional content such as examples, usage, arguments, and other sections present in the Rd file.\nThe function performs the following steps:\n\nParses the Rd file using the Rd2md package.\nCreates a Markdown file with sections for the function’s name, title, and additional content.\nAppends the content to an existing file if append is set to TRUE.\nSaves the resulting Markdown file at the specified location.\n\n\n\nSeealso\nRd2md::parseRd\n\n\nValue\nThis function does not explicitly return any value. It saves the converted Markdown file at the specified location as described in the details section.\n\n\nExamples\n\n# Convert Rd file to Markdown and save it\nlfa_rd_to_md(\"path/to/your/file.Rd\", \"path/to/your/output/file.md\")\n\n# Convert Rd file to Markdown and append to an existing file\nlfa_rd_to_md(\"path/to/your/file.Rd\", \"path/to/existing/output/file.md\", append = TRUE)\n\n\n\nUsage\n\nlfa_rd_to_qmd(rdfile, outfile, append = FALSE)\n\n\n\n\nlfa_rd_to_results\nConvert Rd Files to Markdown and Merge Results\n\nDescription\nThis function converts all Rd (R documentation) files in the “man” directory to Markdown format (.qmd) and saves the converted files in the “results/appendix/package-docs” directory. It then merges the converted Markdown files into a single string and saves the merged content into a file named “docs.qmd” in the “results/appendix/package-docs” directory.\n\n\nDetails\nThe function performs the following steps:\n\nRemoves any existing “docs.qmd” file in the “results/appendix/package-docs” directory.\nFinds all Rd files in the “man” directory.\nConverts each Rd file to Markdown format (.qmd) using the lfa_rd_to_qmd function.\nSaves the converted Markdown files in the “results/appendix/package-docs” directory.\nMerges the content of all converted Markdown files into a single string.\nSaves the merged content into a file named “docs.qmd” in the “results/appendix/package-docs” directory.\n\n\n\nSeealso\nlfa_rd_to_qmd , lfa_merge_and_save\n\n\nValue\nThis function does not explicitly return any value. It performs the conversion, merging, and saving operations as described in the details section.\n\n\nExamples\n\n# Convert Rd files to Markdown and merge the results\nlfa_rd_to_results()\n\n\n\nUsage\n\nlfa_rd_to_results()\n\n\n\n\nlfa_segmentation\nSegment the elements of an point cloud by trees\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nctg\nAn LASCatalog object. If not null, it will perform the actions on this object, if NULL inferring the catalog from the tile_location\n\n\ntile_location\nA tile_location type object holding the information about the location of the catalog. This is used to save the catalog after processing too.\n\n\n\n\n\nAuthor\nJakob Danel\n\n\nDescription\nThis function will try to to divide the hole point cloud into unique trees. Therefore it is assigning for each chunk of the catalog a treeID for each point. Therefore the algorithm uses the li2012 implementation with the following parameters: li2012(dt1 = 2, dt2 = 3, R = 2, Zu = 10, hmin = 5, speed_up = 12) NOTE : The operation is in place and can not be reverted, the old values of the point cloud will be deleted!\n\n\nValue\nA catalog where each chunk has additional treeID values indicating the belonging tree.\n\n\nUsage\n\nlfa_segmentation(ctg, tile_location)\n\n\n\n\nlfa_set_flag\nSet a flag to indicate the completion of a specific process.\n\nArguments\n\n\n\n\n\n\n\nArgument\nDescription\n\n\n\n\nflag_name\nA character string specifying the name of the flag file. It should be a descriptive and unique identifier for the process being flagged.\n\n\n\n\n\nDescription\nThis function creates a hidden flag file at a specified location within the working directory to indicate that a particular processing step has been completed. If the flag file already exists, a warning is issued.\n\n\nValue\nThis function does not have a formal return value.\n\n\nExamples\n\n# Set the flag for a process named \"data_processing\"\nlfa_set_flag(\"data_processing\")\n\n\n\nUsage\n\nlfa_set_flag(flag_name)"
  },
  {
    "objectID": "methods/preprocessing.html",
    "href": "methods/preprocessing.html",
    "title": "",
    "section": "",
    "text": "In this research study, the management and processing of a large dataset are crucial considerations. The dataset’s substantial size necessitates careful maintenance to ensure efficient handling. Furthermore, the data should be easily processable and editable to facilitate necessary corrections and precalculations within the context of our research objectives. To achieve our goals, we have implemented a framework that automatically derives data based on a shapefile, delineating areas of interest. The processed data and results of precalculations are stored in a straightforward manner to enhance accessibility. Additionally, we have designed functions that establish a user-friendly interface, enabling the execution of algorithms on subsets of the data, such as distinct species. These interfaces are not only directly callable by users but can also be integrated into other functions to automate processes. The overarching aim is to streamline the entire preprocessing workflow using a single script, leveraging only the shapefile as a basis. This subsection details the accomplishments of our R-package in realizing these goals, outlining the preprocessing steps undertaken and justifying their necessity in the context of our research.\nThe data are stored in a data subdirectory of the root directory in the format species/location-name/tile-name. To automate the matching of areas of interest with the catalog from the Land NRW1, we utilize the intersecting tool developed by Heisig2. This tool, allows for the automatic retrieval and placement of data downloaded from the Land NRW catalog. To enhance data accessibility, we have devised an object that incorporates species, location name, and tile name (the NRW internal identifier) for each area This object facilitates the specification of the area to be processed. Additionally, we have defined an initialization function that downloads all tiles, returning a list of tile location objects for subsequent processing. A pivotal component of the package’s preprocessing functionality is the map function, which iterates over a list of tile locations (effectively the entire dataset) and accepts a processing function as an argument. The subsequent paragraph outlines the specific preprocessing steps employed, all of which are implemented within the mapping function.\nTo facilitate memory-handling capabilities, each of the tiles, where one area can span multiple tiles, has been split into manageable chunks. We employed a 50x50m size for each tile, resulting in the division of original 1km x 1km files into 400 tiles. These tiles are stored in our directory structure, with each tile housed in a directory named after its tile name and assigned an id as the filename. Implementation-wise, the lidr::catalog_retile function was instrumental in achieving this segmentation. The resulting smaller chunks allow for efficient iteration during subsequent preprocessing steps.\nThe next phase involves reducing our data to the actual size by intersecting the tiles with the defined area of interest. Using the lidR::merge_spatial function, we intersect the area derived from the shapefile, removing all point cloud items outside this region. Due to our tile-wise approach, empty tiles may arise, and in such cases, those tiles are simply deleted.\nFollowing the size reduction to our dataset, the next step involves correcting the z values. The z values in the data are originally relative to the ellipsoid used for referencing, but we require them to be relative to the ground. To achieve this, we utilize the lidR::tin function, which extrapolates a convex hull between all ground points (classified by the data provider) and calculates the z value based on this structure.\nSubsequently, we aim to perform segmentation for each distinct tree, marking each item of the point cloud with a tree ID. We employ the algorithm described by @li2012, using parameters li2012(dt1 = 2, dt2 = 3, R = 2, Zu = 10, hmin = 5, speed_up = 12). The meanings of these parameters are elucidated in Li et al.’s work [@li2012].\nFinally, the last preprocessing step involves individual tree detection, seeking a single POINT object for each tree. The lidR::lmf function, an implementation of the tree data using a local maximum approach, is utilized for this purpose [@popescu2004]. The results are stored in GeoPackage files within our data structure.\nSee ?@sec-appendix-preprocessing for the implementation of the preprocessing."
  },
  {
    "objectID": "methods/preprocessing.html#preprocessing",
    "href": "methods/preprocessing.html#preprocessing",
    "title": "",
    "section": "",
    "text": "In this research study, the management and processing of a large dataset are crucial considerations. The dataset’s substantial size necessitates careful maintenance to ensure efficient handling. Furthermore, the data should be easily processable and editable to facilitate necessary corrections and precalculations within the context of our research objectives. To achieve our goals, we have implemented a framework that automatically derives data based on a shapefile, delineating areas of interest. The processed data and results of precalculations are stored in a straightforward manner to enhance accessibility. Additionally, we have designed functions that establish a user-friendly interface, enabling the execution of algorithms on subsets of the data, such as distinct species. These interfaces are not only directly callable by users but can also be integrated into other functions to automate processes. The overarching aim is to streamline the entire preprocessing workflow using a single script, leveraging only the shapefile as a basis. This subsection details the accomplishments of our R-package in realizing these goals, outlining the preprocessing steps undertaken and justifying their necessity in the context of our research.\nThe data are stored in a data subdirectory of the root directory in the format species/location-name/tile-name. To automate the matching of areas of interest with the catalog from the Land NRW1, we utilize the intersecting tool developed by Heisig2. This tool, allows for the automatic retrieval and placement of data downloaded from the Land NRW catalog. To enhance data accessibility, we have devised an object that incorporates species, location name, and tile name (the NRW internal identifier) for each area This object facilitates the specification of the area to be processed. Additionally, we have defined an initialization function that downloads all tiles, returning a list of tile location objects for subsequent processing. A pivotal component of the package’s preprocessing functionality is the map function, which iterates over a list of tile locations (effectively the entire dataset) and accepts a processing function as an argument. The subsequent paragraph outlines the specific preprocessing steps employed, all of which are implemented within the mapping function.\nTo facilitate memory-handling capabilities, each of the tiles, where one area can span multiple tiles, has been split into manageable chunks. We employed a 50x50m size for each tile, resulting in the division of original 1km x 1km files into 400 tiles. These tiles are stored in our directory structure, with each tile housed in a directory named after its tile name and assigned an id as the filename. Implementation-wise, the lidr::catalog_retile function was instrumental in achieving this segmentation. The resulting smaller chunks allow for efficient iteration during subsequent preprocessing steps.\nThe next phase involves reducing our data to the actual size by intersecting the tiles with the defined area of interest. Using the lidR::merge_spatial function, we intersect the area derived from the shapefile, removing all point cloud items outside this region. Due to our tile-wise approach, empty tiles may arise, and in such cases, those tiles are simply deleted.\nFollowing the size reduction to our dataset, the next step involves correcting the z values. The z values in the data are originally relative to the ellipsoid used for referencing, but we require them to be relative to the ground. To achieve this, we utilize the lidR::tin function, which extrapolates a convex hull between all ground points (classified by the data provider) and calculates the z value based on this structure.\nSubsequently, we aim to perform segmentation for each distinct tree, marking each item of the point cloud with a tree ID. We employ the algorithm described by @li2012, using parameters li2012(dt1 = 2, dt2 = 3, R = 2, Zu = 10, hmin = 5, speed_up = 12). The meanings of these parameters are elucidated in Li et al.’s work [@li2012].\nFinally, the last preprocessing step involves individual tree detection, seeking a single POINT object for each tree. The lidR::lmf function, an implementation of the tree data using a local maximum approach, is utilized for this purpose [@popescu2004]. The results are stored in GeoPackage files within our data structure.\nSee ?@sec-appendix-preprocessing for the implementation of the preprocessing."
  },
  {
    "objectID": "methods/preprocessing.html#footnotes",
    "href": "methods/preprocessing.html#footnotes",
    "title": "",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://www.opengeodata.nrw.de/produkte/geobasis/hm/3dm_l_las/3dm_l_las/, last visited 7th Dec 2023↩︎\nhttps://github.com/joheisig/GEDIcalibratoR, last visited 7th Dec 2023↩︎"
  }
]