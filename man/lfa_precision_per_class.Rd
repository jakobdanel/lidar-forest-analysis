% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/precision_per_class.R
\name{lfa_precision_per_class}
\alias{lfa_precision_per_class}
\title{Calculate Precision per Class from Confusion Matrix}
\usage{
lfa_precision_per_class(confusion_matrix)
}
\arguments{
\item{confusion_matrix}{Confusion matrix obtained from a classification evaluation.}
}
\value{
A numeric vector representing precision for each class.
}
\description{
This function calculates precision for each class based on the provided confusion matrix.
}
\details{
Precision is a measure of the accuracy of the positive predictions for a specific class. It is calculated as the ratio of true positives to the sum of true positives and false positives.
}
\examples{
# Example confusion matrix
cm <- table(predicted = c("A", "B", "A", "B"), actual = c("A", "A", "B", "B"))
# Calculate precision per class
precision_vector <- lfa_precision_per_class(cm)

}
\seealso{
\code{\link{lfa_recall_per_class}}, \code{\link{lfa_f1_score_per_class}}
}
